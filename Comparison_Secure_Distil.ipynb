{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ce38de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secure: % sotto soglia (dovrebbe essere ~0 se hai gi√† filtrato): 0.0\n",
      "Distil: % sotto soglia (dovrebbe essere ~0 se hai gi√† filtrato): 0.0\n",
      "\n",
      "=== OVERLAP METRICS ===\n",
      "Secure retained: 367,457\n",
      "Distil retained: 102,654\n",
      "Intersection:    85,099\n",
      "Union:           385,012\n",
      "% Distil covered by Secure (|D‚à©S|/|D|): 82.90%\n",
      "% Secure covered by Distil (|D‚à©S|/|S|): 23.16%\n",
      "Jaccard (|D‚à©S|/|D‚à™S|): 0.2210\n",
      "\n",
      "=== TOP GROUPS BY (Secure - Distil) ===\n",
      "                                            chat_name  secure_n  distil_n  \\\n",
      "7                                           Only Dark    155579     49962   \n",
      "9                                 –¢–µ–Ω–µ–≤–æ–π –î–∞—Ä–∫–Ω–µ—Ç –ß–∞—Ç     70883     14518   \n",
      "11                                       –ß–∞—Ç –¥–æ–∫—Å–µ—Ä–æ–≤     63242      8548   \n",
      "1                                            DDOS‰∫§ÊµÅÊîªÂáª     41765     12509   \n",
      "10                          –•–∞–∫–µ—Ä—ã |–ß–∞—Ç| ùìóùì™ùì¨ùì¥ùìÆùìªùìº ùì¨ùì±ùì™ùìΩ     16344      1654   \n",
      "6                                   Mikrotik-Training      8831      1814   \n",
      "8                                     VirusCheck Chat      4670       783   \n",
      "4                                    HackDroids ‚Äî –ß–∞—Ç       231        33   \n",
      "5                                       Hacking Realm       288       403   \n",
      "0   Cyber Security - Information Security - IT Sec...       298       739   \n",
      "\n",
      "    intersection_n  delta_S_minus_D  pct_D_in_S  pct_S_in_D  \n",
      "7            46851           105617   93.773268   30.113961  \n",
      "9            13556            56365   93.373743   19.124473  \n",
      "11            4997            54694   58.458119    7.901395  \n",
      "1            12456            29256   99.576305   29.824015  \n",
      "10             782            14690   47.279323    4.784630  \n",
      "6             1355             7017   74.696803   15.343676  \n",
      "8              478             3887   61.047254   10.235546  \n",
      "4               22              198   66.666667    9.523810  \n",
      "5              206             -115   51.116625   71.527778  \n",
      "0              202             -441   27.334235   67.785235  \n",
      "\n",
      "=== DISCORDANT COUNTS ===\n",
      "Only Secure: 282,358\n",
      "Only Distil: 17,555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apisp\\AppData\\Local\\Temp\\ipykernel_21692\\423543095.py:149: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_url\"] = df[\"text\"].astype(str).str.contains(r\"(https?://|www\\.)\", regex=True)\n",
      "C:\\Users\\apisp\\AppData\\Local\\Temp\\ipykernel_21692\\423543095.py:149: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_url\"] = df[\"text\"].astype(str).str.contains(r\"(https?://|www\\.)\", regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONLY SECURE SUMMARY ===\n",
      "N: 282,358\n",
      "text_len (mean/median): 213.38 / 146.0\n",
      "word_len (mean/median): 28.25 / 21.0\n",
      "has_url: 1.70%\n",
      "has_cve: 0.00%\n",
      "has_ip: 0.06%\n",
      "has_domain_like: 0.11%\n",
      "\n",
      "=== ONLY DISTIL SUMMARY ===\n",
      "N: 17,555\n",
      "text_len (mean/median): 156.17 / 41.0\n",
      "word_len (mean/median): 21.93 / 6.0\n",
      "has_url: 2.09%\n",
      "has_cve: 0.00%\n",
      "has_ip: 2.49%\n",
      "has_domain_like: 0.85%\n",
      "\n",
      "Saved reports to: C:\\Users\\apisp\\OneDrive\\Desktop\\PoliTo\\II Anno\\DPA\\IoC_on_Telegram\\compare_reports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 0) CONFIG\n",
    "# =========================\n",
    "# Metti qui i tuoi file o folder (supporta anche wildcard)\n",
    "DISTIL_PATH = r\"SECUREBERT/1-CTI_DATASET.csv\"\n",
    "SECURE_PATH = r\"SECUREBERT/SECURE_DBS/1-CTI_DATASET.csv\"\n",
    "\n",
    "# Chiave per matchare lo stesso messaggio tra dataset\n",
    "# Consigliato: (group_id, msg_id) o (chat_name, msg_id)\n",
    "KEY_COLS = [\"group_id\", \"msg_id\"]\n",
    "\n",
    "# Soglia (se vuoi controllare / ricalcolare)\n",
    "THRESH = 0.60\n",
    "\n",
    "# =========================\n",
    "# 1) LOAD (singolo file o wildcard)\n",
    "# =========================\n",
    "def load_many(path_pattern: str) -> pd.DataFrame:\n",
    "    paths = sorted(Path().glob(path_pattern))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"Nessun file trovato per pattern: {path_pattern}\")\n",
    "    dfs = [pd.read_csv(p) for p in paths]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "secure = load_many(SECURE_PATH)\n",
    "distil = load_many(DISTIL_PATH)\n",
    "\n",
    "# Normalizza tipi e colonne chiave\n",
    "for df, name in [(secure, \"secure\"), (distil, \"distil\")]:\n",
    "    missing = [c for c in KEY_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Mancano colonne chiave {missing} in dataset {name}\")\n",
    "    # msg_id spesso √® int, ma per sicurezza lo forziamo a stringa uniforme\n",
    "    df[\"msg_id\"] = df[\"msg_id\"].astype(str)\n",
    "    df[\"group_id\"] = df[\"group_id\"].astype(str)\n",
    "\n",
    "# (Opzionale) se vuoi verificare che i CSV rispettino gi√† la soglia:\n",
    "if \"cyber_score\" in secure.columns:\n",
    "    print(\"Secure: % sotto soglia (dovrebbe essere ~0 se hai gi√† filtrato):\",\n",
    "          (secure[\"cyber_score\"] < THRESH).mean())\n",
    "if \"cyber_score\" in distil.columns:\n",
    "    print(\"Distil: % sotto soglia (dovrebbe essere ~0 se hai gi√† filtrato):\",\n",
    "          (distil[\"cyber_score\"] < THRESH).mean())\n",
    "\n",
    "# Dedup: nel caso in cui lo stesso msg sia comparso pi√π volte\n",
    "secure = secure.drop_duplicates(subset=KEY_COLS).copy()\n",
    "distil = distil.drop_duplicates(subset=KEY_COLS).copy()\n",
    "\n",
    "# =========================\n",
    "# 2) SET METRICS (overlap)\n",
    "# =========================\n",
    "secure_keys = set(map(tuple, secure[KEY_COLS].to_numpy()))\n",
    "distil_keys = set(map(tuple, distil[KEY_COLS].to_numpy()))\n",
    "\n",
    "inter = secure_keys & distil_keys\n",
    "union = secure_keys | distil_keys\n",
    "\n",
    "nS = len(secure_keys)\n",
    "nD = len(distil_keys)\n",
    "nI = len(inter)\n",
    "nU = len(union)\n",
    "\n",
    "pct_D_in_S = (nI / nD) * 100 if nD else 0\n",
    "pct_S_in_D = (nI / nS) * 100 if nS else 0\n",
    "jaccard = (nI / nU) if nU else 0\n",
    "\n",
    "print(\"\\n=== OVERLAP METRICS ===\")\n",
    "print(f\"Secure retained: {nS:,}\")\n",
    "print(f\"Distil retained: {nD:,}\")\n",
    "print(f\"Intersection:    {nI:,}\")\n",
    "print(f\"Union:           {nU:,}\")\n",
    "print(f\"% Distil covered by Secure (|D‚à©S|/|D|): {pct_D_in_S:.2f}%\")\n",
    "print(f\"% Secure covered by Distil (|D‚à©S|/|S|): {pct_S_in_D:.2f}%\")\n",
    "print(f\"Jaccard (|D‚à©S|/|D‚à™S|): {jaccard:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# 3) BREAKDOWN PER GROUP\n",
    "# =========================\n",
    "# Conteggio per gruppo\n",
    "Sg = secure.groupby(\"chat_name\", dropna=False).size().rename(\"secure_n\").reset_index()\n",
    "Dg = distil.groupby(\"chat_name\", dropna=False).size().rename(\"distil_n\").reset_index()\n",
    "\n",
    "# Intersection per gruppo: facciamo merge sulle chiavi e contiamo\n",
    "merged = secure[KEY_COLS + [\"chat_name\"]].merge(\n",
    "    distil[KEY_COLS + [\"chat_name\"]],\n",
    "    on=KEY_COLS,\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_S\", \"_D\"),\n",
    ")\n",
    "Ig = merged.groupby(\"chat_name_S\", dropna=False).size().rename(\"intersection_n\").reset_index()\n",
    "Ig = Ig.rename(columns={\"chat_name_S\": \"chat_name\"})\n",
    "\n",
    "by_group = Sg.merge(Dg, on=\"chat_name\", how=\"outer\").merge(Ig, on=\"chat_name\", how=\"left\")\n",
    "by_group = by_group.fillna(0)\n",
    "by_group[\"secure_n\"] = by_group[\"secure_n\"].astype(int)\n",
    "by_group[\"distil_n\"] = by_group[\"distil_n\"].astype(int)\n",
    "by_group[\"intersection_n\"] = by_group[\"intersection_n\"].astype(int)\n",
    "\n",
    "# percentuali per gruppo\n",
    "by_group[\"pct_D_in_S\"] = np.where(by_group[\"distil_n\"] > 0,\n",
    "                                  100 * by_group[\"intersection_n\"] / by_group[\"distil_n\"],\n",
    "                                  0)\n",
    "by_group[\"pct_S_in_D\"] = np.where(by_group[\"secure_n\"] > 0,\n",
    "                                  100 * by_group[\"intersection_n\"] / by_group[\"secure_n\"],\n",
    "                                  0)\n",
    "\n",
    "# ordina per divergenza: (secure - distil) o solo secure\n",
    "by_group[\"delta_S_minus_D\"] = by_group[\"secure_n\"] - by_group[\"distil_n\"]\n",
    "\n",
    "print(\"\\n=== TOP GROUPS BY (Secure - Distil) ===\")\n",
    "print(by_group.sort_values(\"delta_S_minus_D\", ascending=False)\n",
    "      .head(10)[[\"chat_name\", \"secure_n\", \"distil_n\", \"intersection_n\", \"delta_S_minus_D\", \"pct_D_in_S\", \"pct_S_in_D\"]])\n",
    "\n",
    "# =========================\n",
    "# 4) DISCORDANT SETS: only-secure / only-distil\n",
    "# =========================\n",
    "only_secure_keys = secure_keys - distil_keys\n",
    "only_distil_keys = distil_keys - secure_keys\n",
    "\n",
    "only_secure = secure.merge(\n",
    "    pd.DataFrame(list(only_secure_keys), columns=KEY_COLS),\n",
    "    on=KEY_COLS,\n",
    "    how=\"inner\"\n",
    ")\n",
    "only_distil = distil.merge(\n",
    "    pd.DataFrame(list(only_distil_keys), columns=KEY_COLS),\n",
    "    on=KEY_COLS,\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== DISCORDANT COUNTS ===\")\n",
    "print(f\"Only Secure: {len(only_secure):,}\")\n",
    "print(f\"Only Distil: {len(only_distil):,}\")\n",
    "\n",
    "# =========================\n",
    "# 5) SIMPLE TEXT STATS + PATTERN COUNTS (discordant analysis)\n",
    "# =========================\n",
    "def add_text_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"text_len\"] = df[\"text\"].astype(str).str.len()\n",
    "    df[\"word_len\"] = df[\"text\"].astype(str).str.split().apply(len)\n",
    "\n",
    "    # pattern \"grezzi\" (non IoC extraction completa, solo indicatori veloci)\n",
    "    df[\"has_url\"] = df[\"text\"].astype(str).str.contains(r\"(https?://|www\\.)\", regex=True)\n",
    "    df[\"has_cve\"] = df[\"text\"].astype(str).str.contains(r\"\\bCVE-\\d{4}-\\d+\\b\", regex=True, case=False)\n",
    "    df[\"has_ip\"]  = df[\"text\"].astype(str).str.contains(r\"\\b\\d{1,3}(?:\\.\\d{1,3}){3}\\b\", regex=True)\n",
    "    df[\"has_domain_like\"] = df[\"text\"].astype(str).str.contains(\n",
    "        r\"\\b(?:[a-zA-Z0-9-]+\\.)+(?:com|org|net|io|ru|cn|it|uk|gov)\\b\",\n",
    "        regex=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "only_secure = add_text_stats(only_secure)\n",
    "only_distil = add_text_stats(only_distil)\n",
    "\n",
    "def summarize(df: pd.DataFrame, name: str):\n",
    "    if df.empty:\n",
    "        print(f\"\\n[{name}] dataset vuoto.\")\n",
    "        return\n",
    "    print(f\"\\n=== {name} SUMMARY ===\")\n",
    "    print(f\"N: {len(df):,}\")\n",
    "    print(\"text_len (mean/median):\", df[\"text_len\"].mean().round(2), \"/\", df[\"text_len\"].median())\n",
    "    print(\"word_len (mean/median):\", df[\"word_len\"].mean().round(2), \"/\", df[\"word_len\"].median())\n",
    "    for col in [\"has_url\", \"has_cve\", \"has_ip\", \"has_domain_like\"]:\n",
    "        print(f\"{col}: {(df[col].mean()*100):.2f}%\")\n",
    "\n",
    "summarize(only_secure, \"ONLY SECURE\")\n",
    "summarize(only_distil, \"ONLY DISTIL\")\n",
    "\n",
    "# =========================\n",
    "# 6) OPTIONAL: SAVE REPORT CSVs\n",
    "# =========================\n",
    "out_dir = Path(\"compare_reports\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "by_group.sort_values(\"delta_S_minus_D\", ascending=False).to_csv(out_dir / \"by_group_overlap.csv\", index=False)\n",
    "only_secure.to_csv(out_dir / \"only_secure.csv\", index=False)\n",
    "only_distil.to_csv(out_dir / \"only_distil.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved reports to: {out_dir.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
