{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Cerco file CSV nella cartella: ./Results_CSV...\n",
      "ðŸ“‹ Trovati 12 file. Inizio unione...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Concatenazione in corso...\n",
      "ðŸ“Š Statistiche Finali:\n",
      "   - File uniti: 12\n",
      "   - Totale righe grezze: 219727\n",
      "   - Totale righe uniche: 219727\n",
      "   - Colonne: ['message_id', 'date', 'user', 'text', 'score']\n",
      "\n",
      "âœ… SUCCESS! Dataset completo salvato come: FULL_CYBER_DATASET_MERGED.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURAZIONE\n",
    "# ==============================================================================\n",
    "CARTELLA_INPUT = \"./Results_CSV\"\n",
    "NOME_FILE_OUTPUT = \"FULL_CYBER_DATASET_MERGED.csv\"\n",
    "\n",
    "# ==============================================================================\n",
    "# LOGICA DI UNIONE\n",
    "# ==============================================================================\n",
    "print(f\"ðŸ“‚ Cerco file CSV nella cartella: {CARTELLA_INPUT}...\")\n",
    "\n",
    "# Trova tutti i file .csv usando glob\n",
    "files = glob.glob(os.path.join(CARTELLA_INPUT, \"*.csv\"))\n",
    "\n",
    "if not files:\n",
    "    print(\"âŒ ERRORE: Nessun file CSV trovato. Controlla il percorso.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"ðŸ“‹ Trovati {len(files)} file. Inizio unione...\")\n",
    "\n",
    "lista_dataframe = []\n",
    "totale_messaggi = 0\n",
    "\n",
    "# Ciclo su ogni file con barra di progresso\n",
    "for file in tqdm(files, desc=\"Merging\"):\n",
    "    try:\n",
    "        # Legge il singolo CSV\n",
    "        df_temp = pd.read_csv(file)\n",
    "        \n",
    "        # Se il file non Ã¨ vuoto, lo aggiungiamo alla lista\n",
    "        if not df_temp.empty:\n",
    "            lista_dataframe.append(df_temp)\n",
    "            totale_messaggi += len(df_temp)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Errore leggendo il file {file}: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CONCATENAZIONE E SALVATAGGIO\n",
    "# ==============================================================================\n",
    "if lista_dataframe:\n",
    "    print(\"\\nðŸ”„ Concatenazione in corso...\")\n",
    "    # Unisce tutti i pezzi in un unico DataFrame gigante\n",
    "    df_finale = pd.concat(lista_dataframe, ignore_index=True)\n",
    "    \n",
    "    # (Opzionale) Rimuove eventuali duplicati esatti se lo stesso messaggio Ã¨ stato salvato due volte\n",
    "    df_finale = df_finale.drop_duplicates()\n",
    "    \n",
    "    print(f\"ðŸ“Š Statistiche Finali:\")\n",
    "    print(f\"   - File uniti: {len(files)}\")\n",
    "    print(f\"   - Totale righe grezze: {totale_messaggi}\")\n",
    "    print(f\"   - Totale righe uniche: {len(df_finale)}\")\n",
    "    print(f\"   - Colonne: {list(df_finale.columns)}\")\n",
    "    \n",
    "    # Salvataggio\n",
    "    df_finale.to_csv(NOME_FILE_OUTPUT, index=False)\n",
    "    print(f\"\\nâœ… SUCCESS! Dataset completo salvato come: {NOME_FILE_OUTPUT}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Nessun dato valido trovato da unire.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e0b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Caricamento dataset: FULL_CYBER_DATASET_MERGED.csv...\n",
      "ðŸ“‹ Messaggi da analizzare: 219727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mining & Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 219727/219727 [01:29<00:00, 2446.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ… ESTRAZIONE COMPLETATA\n",
      "ðŸ”¹ IoC Totali trovati (grezzi): 624\n",
      "ðŸ§¹ IoC Scartati (Whitelist):   2546\n",
      "ðŸ”¹ IoC Unici salvati:          305\n",
      "==================================================\n",
      "\n",
      "Tipologie rimaste:\n",
      "ioc_type\n",
      "URL (Dirty)     218\n",
      "IPv4 (Loose)     67\n",
      "MD5 Hash         20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ’¾ File pulito salvato: FINAL_IOC_REPORT_WHITELISTED.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from iocsearcher.searcher import Searcher\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURAZIONE\n",
    "# ==============================================================================\n",
    "INPUT_FILE = \"FULL_CYBER_DATASET_MERGED.csv\" \n",
    "OUTPUT_FILE = \"FINAL_IOC_REPORT_WHITELISTED.csv\"\n",
    "\n",
    "# --- WHITELIST (LISTA DEI BUONI) ---\n",
    "# Se un URL contiene una di queste parole, viene SCARTATO.\n",
    "# Puoi aggiungere o togliere domini da questa lista.\n",
    "WHITELIST_DOMAINS = [\n",
    "    \"t.me\", \"telegram.me\",       # Link interni Telegram\n",
    "    \"youtube.com\", \"youtu.be\",   # Video\n",
    "    \"facebook.com\", \"fb.com\",    # Social\n",
    "    \"instagram.com\", \n",
    "    \"twitter.com\", \"x.com\",\n",
    "    \"tiktok.com\",\n",
    "    \"linkedin.com\",\n",
    "    \"whatsapp.com\",\n",
    "    \"google.com\", \"goo.gl\",      # Google Services (Attenzione: a volte usati per phishing)\n",
    "    \"gmail.com\",\n",
    "    \"netflix.com\",\n",
    "    \"spotify.com\",\n",
    "    \"amazon.com\",\n",
    "    \"apple.com\",\n",
    "    \"microsoft.com\",\n",
    "    \"github.com\", \"gitlab.com\",  # Code repo (Attenzione: spesso ospitano malware, ma se vuoi pulire togli)\n",
    "    \"play.google.com\",           # App Store ufficiali\n",
    "    \"discord.com\", \"discord.gg\",\n",
    "    \"zoom.us\",\n",
    "    \"wikipedia.org\"\n",
    "]\n",
    "\n",
    "# Inizializza la libreria standard\n",
    "searcher = Searcher()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. REGEX E FUNZIONI DI FILTRO\n",
    "# ==============================================================================\n",
    "REGEX_URL_GREEDY = r'https?://\\S+' \n",
    "REGEX_IP_LOOSE = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b'\n",
    "REGEX_MD5 = r'\\b[a-fA-F0-9]{32}\\b'\n",
    "\n",
    "def is_whitelisted(ioc_value):\n",
    "    \"\"\"Ritorna True se l'IoC contiene un dominio in whitelist\"\"\"\n",
    "    ioc_lower = str(ioc_value).lower()\n",
    "    for domain in WHITELIST_DOMAINS:\n",
    "        if domain in ioc_lower:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MOTORE DI ESTRAZIONE\n",
    "# ==============================================================================\n",
    "print(f\"ðŸ”„ Caricamento dataset: {INPUT_FILE}...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"ðŸ“‹ Messaggi da analizzare: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Errore: File non trovato. Esegui prima l'unione dei CSV.\")\n",
    "    exit()\n",
    "\n",
    "extracted_iocs = []\n",
    "stats = {\"trovati\": 0, \"scartati_whitelist\": 0}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Mining & Filtering\"):\n",
    "    text = str(row.get('text', ''))\n",
    "    if len(text) < 5: continue\n",
    "    \n",
    "    meta = {\n",
    "        \"group_name\": row.get('group_name', 'Unknown'),\n",
    "        \"date\": row.get('date', ''),\n",
    "        \"user_id\": row.get('user_id', ''),\n",
    "        \"original_text\": text\n",
    "    }\n",
    "\n",
    "    # --- A. IOCSEARCHER ---\n",
    "    found_standard = []\n",
    "    try:\n",
    "        iocs_list = searcher.search_raw(text)\n",
    "        if iocs_list:\n",
    "            for ioc_type, ioc_value in iocs_list:\n",
    "                \n",
    "                # CHECK WHITELIST\n",
    "                if is_whitelisted(ioc_value):\n",
    "                    stats[\"scartati_whitelist\"] += 1\n",
    "                    continue # Salta questo giro\n",
    "                \n",
    "                found_standard.append(ioc_value)\n",
    "                extracted_iocs.append({**meta, \"ioc_type\": ioc_type, \"ioc_value\": ioc_value, \"source\": \"lib-iocsearcher\"})\n",
    "                stats[\"trovati\"] += 1\n",
    "    except: pass\n",
    "\n",
    "    # --- B. REGEX MANUALE ---\n",
    "    \n",
    "    # URL Sporchi\n",
    "    dirty_urls = re.findall(REGEX_URL_GREEDY, text)\n",
    "    for url in dirty_urls:\n",
    "        # Filtro duplicati + Whitelist\n",
    "        if not any(url in standard for standard in found_standard):\n",
    "            if is_whitelisted(url):\n",
    "                stats[\"scartati_whitelist\"] += 1\n",
    "                continue\n",
    "                \n",
    "            extracted_iocs.append({**meta, \"ioc_type\": \"URL (Dirty)\", \"ioc_value\": url, \"source\": \"regex-greedy\"})\n",
    "            stats[\"trovati\"] += 1\n",
    "\n",
    "    # IP Loose\n",
    "    loose_ips = re.findall(REGEX_IP_LOOSE, text)\n",
    "    for ip in loose_ips:\n",
    "        # Semplice filtro per IP locali (192.168.x.x e 127.0.0.1) che sono rumore\n",
    "        if ip.startswith(\"192.168.\") or ip.startswith(\"127.\") or ip.startswith(\"10.\"):\n",
    "            continue\n",
    "            \n",
    "        if ip not in found_standard:\n",
    "            extracted_iocs.append({**meta, \"ioc_type\": \"IPv4 (Loose)\", \"ioc_value\": ip, \"source\": \"regex-loose\"})\n",
    "            stats[\"trovati\"] += 1\n",
    "\n",
    "    # Hash\n",
    "    hashes = re.findall(REGEX_MD5, text)\n",
    "    for h in hashes:\n",
    "        if h not in found_standard:\n",
    "            extracted_iocs.append({**meta, \"ioc_type\": \"MD5 Hash\", \"ioc_value\": h, \"source\": \"regex-md5\"})\n",
    "            stats[\"trovati\"] += 1\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. PULIZIA E SALVATAGGIO\n",
    "# ==============================================================================\n",
    "if extracted_iocs:\n",
    "    df_result = pd.DataFrame(extracted_iocs)\n",
    "    df_result = df_result.drop_duplicates(subset=['ioc_value'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"âœ… ESTRAZIONE COMPLETATA\")\n",
    "    print(f\"ðŸ”¹ IoC Totali trovati (grezzi): {stats['trovati']}\")\n",
    "    print(f\"ðŸ§¹ IoC Scartati (Whitelist):   {stats['scartati_whitelist']}\")\n",
    "    print(f\"ðŸ”¹ IoC Unici salvati:          {len(df_result)}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nTipologie rimaste:\")\n",
    "    print(df_result['ioc_type'].value_counts())\n",
    "    \n",
    "    df_result.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nðŸ’¾ File pulito salvato: {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"\\nâŒ Nessun IoC trovato dopo il filtraggio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd52ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FINAL_IOC_REPORT_HYBRID.csv')\n",
    "df = df.drop_duplicates('ioc_value')\n",
    "df.to_csv('FINAL_IOC_REPORT_HYBRID2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
