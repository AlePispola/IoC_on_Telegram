{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-25T08:34:24.597515Z",
     "iopub.status.busy": "2025-11-25T08:34:24.597216Z",
     "iopub.status.idle": "2025-11-25T08:35:04.503908Z",
     "shell.execute_reply": "2025-11-25T08:35:04.502697Z",
     "shell.execute_reply.started": "2025-11-25T08:34:24.597487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 08:34:31.667154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764059672.048858      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764059672.168028      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Stai utilizzando: CUDA\n",
      "‚¨áÔ∏è Scaricando APTNER direttamente da GitHub...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP E DOWNLOAD DIRETTO (BYPASS DEFENDER)\n",
    "# ==========================================\n",
    "%pip install -q transformers datasets emoji accelerate > /dev/null 2>&1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "# Verifica GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Stai utilizzando: {device.upper()}\")\n",
    "\n",
    "# --- DOWNLOAD DATI DA GITHUB A KAGGLE ---\n",
    "# Scarichiamo i raw file direttamente nella cartella di lavoro di Kaggle (/kaggle/working/)\n",
    "print(\"‚¨áÔ∏è Scaricando APTNER direttamente da GitHub...\")\n",
    "!wget -q https://raw.githubusercontent.com/wangxuren/APTNER/master/APTNERtrain.txt -O /kaggle/working/train.txt\n",
    "!wget -q https://raw.githubusercontent.com/wangxuren/APTNER/master/APTNERtest.txt -O /kaggle/working/test.txt\n",
    "\n",
    "# Definiamo i percorsi dei file appena scaricati\n",
    "FILE_TRAIN = \"/kaggle/working/train.txt\"\n",
    "FILE_TEST = \"/kaggle/working/test.txt\"\n",
    "MODELLO_BASE = \"ehsanaghaei/SecureBERT\"\n",
    "\n",
    "print(\"‚¨áÔ∏è Scaricamento APTNER completato!\")\n",
    "\n",
    "# --- FUNZIONI (Clean & Parser) ---\n",
    "def clean_and_mask(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    \n",
    "    # 1. Rimuovi Emoji\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    # --- NUOVA REGOLA: MASCHERA LE CVE ---\n",
    "    # Trasforma \"CVE-2023-4455\" o \"CVE-2021-100\" in \"[CVE]\"\n",
    "    # Il modello imparer√† che il token [CVE] √® SEMPRE una cosa brutta.\n",
    "    text = re.sub(r'CVE-\\d{4}-\\d+', '[CVE]', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 2. Maschera Link Telegram\n",
    "    text = re.sub(r'(?:https?://)?(?:www\\.)?(?:t\\.me|telegram\\.me)/[a-zA-Z0-9_]+', '[TG_LINK]', text)\n",
    "    \n",
    "    # 3. Maschera URL standard\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[URL]', text)\n",
    "    \n",
    "    # 4. Maschera IP Address (IPv4)\n",
    "    text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '[IP]', text)\n",
    "    \n",
    "    # 5. Maschera Domini generici\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z0-9-]+\\.)+(?:com|org|net|io|ru|cn|it|uk|gov)\\b', '[DOMAIN]', text)\n",
    "    \n",
    "    # 6. Pulizia spazi\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def processa_aptner_multiplo(lista_files):\n",
    "    all_sentences = []\n",
    "    all_labels = []\n",
    "    for input_file in lista_files:\n",
    "        print(f\"üîÑ Processando {os.path.basename(input_file)}...\")\n",
    "        if not os.path.exists(input_file): continue\n",
    "        \n",
    "        current_words = []\n",
    "        has_entity = False \n",
    "        with open(input_file, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_words:\n",
    "                    full_sentence = \" \".join(current_words)\n",
    "                    label = 1 if has_entity else 0\n",
    "                    all_sentences.append(full_sentence)\n",
    "                    all_labels.append(label)\n",
    "                    current_words = []\n",
    "                    has_entity = False\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2: continue\n",
    "            if parts[-1] != 'O': has_entity = True\n",
    "            current_words.append(parts[0])\n",
    "    return pd.DataFrame({'text': all_sentences, 'label': all_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T08:52:02.239732Z",
     "iopub.status.busy": "2025-11-25T08:52:02.239092Z",
     "iopub.status.idle": "2025-11-25T08:52:08.983966Z",
     "shell.execute_reply": "2025-11-25T08:52:08.983297Z",
     "shell.execute_reply.started": "2025-11-25T08:52:02.239709Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Caricamento file locali...\n",
      "üîÑ Processando train.txt...\n",
      "üîÑ Processando test.txt...\n",
      "‚úÖ APTNER (Cyber Only): 7006 frasi.\n",
      "üíâ Iniettando esempi di Vulnerabilit√† (CVE) per migliorare il modello...\n",
      "‚úÖ Aggiunti 10 esempi di CVE. Totale Cyber: 7016\n",
      "‚¨áÔ∏è Scaricando dataset Rumore Misto (SMS + Dialoghi)...\n",
      "   2. Caricamento Reddit (go_emotions)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f6ef59d5394930843c616aee8fe6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e794802fa9db45bf947d8bead170c445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "simplified/train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fa9639e8614392a289db73f13cf46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "simplified/validation-00000-of-00001.par(‚Ä¶):   0%|          | 0.00/350k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7489dfaa0fc46e592029c2fa0806ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "simplified/test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e7831757c24412b6a301a9b58cf992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac0a4bfd2144461b8f4c4f6fdc4edd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2540cd0121924b81b047ec3f9651a973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3. Fusione dataset...\n",
      "‚úÖ Bilanciamento perfetto: estratti 7016 messaggi di rumore su 48984 totali.\n",
      "‚úÖ Dataset Rumore Pronto.\n",
      "   Esempio (SMS): Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "   Esempio (Reddit): My favourite food is anything I didn't have to cook myself.\n",
      "üßπ Unione con Cyber e Masking...\n",
      "üíæ Dataset salvato per verifica in 'dataset_training_final.csv'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. CARICAMENTO DATI (AGGIORNATO CON CHAT REALI)\n",
    "# ==========================================\n",
    "\n",
    "# A. Caricamento APTNER (dai file scaricati col codice sopra)\n",
    "print(\"üìÇ Caricamento file locali...\")\n",
    "# Assicurati che FILE_TRAIN e FILE_TEST siano definiti nella cella precedente\n",
    "# Se d√† errore qui, controlla di aver eseguito la Cella 1\n",
    "df_cyber = processa_aptner_multiplo([FILE_TRAIN, FILE_TEST])\n",
    "\n",
    "# FILTRO: Solo frasi con entit√† (Label 1)\n",
    "df_cyber = df_cyber[df_cyber['label'] == 1]\n",
    "print(f\"‚úÖ APTNER (Cyber Only): {len(df_cyber)} frasi.\")\n",
    "\n",
    "# ==========================================\n",
    "# DATA AUGMENTATION: INIEZIONE CVE\n",
    "# ==========================================\n",
    "print(\"üíâ Iniettando esempi di Vulnerabilit√† (CVE) per migliorare il modello...\")\n",
    "\n",
    "cve_data = [\n",
    "    \"Critical vulnerability CVE-2023-2251 found in Windows Server.\",\n",
    "    \"Please patch immediately against CVE-2024-1001 to prevent remote code execution.\",\n",
    "    \"Zero-day exploit detected targeting CVE-2021-44228 (Log4Shell).\",\n",
    "    \"New proof of concept available for CVE-2023-0001 on GitHub.\",\n",
    "    \"Hackers are scanning for unpatched systems with CVE-2022-9999.\",\n",
    "    \"The new update fixes CVE-2023-5555 and strictly sanitizes input.\",\n",
    "    \"Warning: Ransomware groups are exploiting CVE-2024-3000.\",\n",
    "    \"Buffer overflow vulnerability identified as CVE-2020-1234.\",\n",
    "    \"Check if your firewall blocks attempts related to CVE-2025-0001.\",\n",
    "    \"High severity flaw CVE-2023-9876 allows unauthorized access.\"\n",
    "]\n",
    "\n",
    "# Creiamo un mini-dataframe con Label 1 (Cyber)\n",
    "df_cve = pd.DataFrame({'text': cve_data, 'label': [1] * len(cve_data)})\n",
    "\n",
    "# Lo aggiungiamo al dataset Cyber originale\n",
    "df_cyber = pd.concat([df_cyber, df_cve], ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Aggiunti {len(df_cve)} esempi di CVE. Totale Cyber: {len(df_cyber)}\")\n",
    "\n",
    "# ==========================================\n",
    "# B. CARICAMENTO RUMORE (POTENZIATO: SMS + DAILY DIALOG)\n",
    "# ==========================================\n",
    "print(\"‚¨áÔ∏è Scaricando dataset Rumore Misto (SMS + Dialoghi)...\")\n",
    "\n",
    "# 1. Dataset SMS SPAM (Chat brevi, slang) - Ne prendiamo TUTTI quelli disponibili\n",
    "dataset_sms = load_dataset(\"sms_spam\", split=\"train\")\n",
    "df_sms = pd.DataFrame(dataset_sms)\n",
    "df_sms = df_sms.rename(columns={'sms': 'text'})\n",
    "df_sms['label'] = 0\n",
    "\n",
    "# --- 2. DATASET GO_EMOTIONS (Reddit - Per discussioni e chat) ---\n",
    "print(\"   2. Caricamento Reddit (go_emotions)...\")\n",
    "# Questo √® nativo e sicuro, non dar√† errori di script\n",
    "dataset_reddit = load_dataset(\"go_emotions\", split=\"train\")\n",
    "df_reddit = pd.DataFrame(dataset_reddit)\n",
    "df_reddit = df_reddit[['text']] # Teniamo solo il testo\n",
    "df_reddit['label'] = 0\n",
    "\n",
    "# --- 3. UNIONE E PULIZIA ---\n",
    "print(\"   3. Fusione dataset...\")\n",
    "# Uniamo SMS e Reddit\n",
    "df_noise = pd.concat([df_sms, df_reddit], ignore_index=True)\n",
    "\n",
    "# Pulizia: Rimuoviamo messaggi troppo corti o tag di rimozione reddit\n",
    "df_noise = df_noise[df_noise['text'].str.len() > 4]\n",
    "df_noise = df_noise[df_noise['text'] != '[deleted]']\n",
    "df_noise = df_noise[df_noise['text'] != '[removed]']\n",
    "\n",
    "# --- 4. BILANCIAMENTO ---\n",
    "# Vogliamo che il rumore sia pari ai dati Cyber (circa 7000)\n",
    "target_size = len(df_cyber)\n",
    "\n",
    "if len(df_noise) > target_size:\n",
    "    # Abbiamo tantissimi dati (5k SMS + 58k Reddit), quindi campioniamo\n",
    "    df_noise = df_noise.sample(n=target_size, random_state=42)\n",
    "    print(f\"‚úÖ Bilanciamento perfetto: estratti {target_size} messaggi di rumore su {len(df_sms)+len(df_reddit)} totali.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Nota: Usiamo tutto il rumore disponibile ({len(df_noise)} frasi).\")\n",
    "\n",
    "print(f\"‚úÖ Dataset Rumore Pronto.\")\n",
    "print(f\"   Esempio (SMS): {df_sms.iloc[0]['text'] if not df_sms.empty else 'N/A'}\")\n",
    "print(f\"   Esempio (Reddit): {df_reddit.iloc[0]['text']}\")\n",
    "\n",
    "# ==========================================\n",
    "# C. UNIONE FINALE E PREPROCESSING\n",
    "# ==========================================\n",
    "print(\"üßπ Unione con Cyber e Masking...\")\n",
    "df_full = pd.concat([df_cyber, df_noise]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Applichiamo la pulizia\n",
    "df_full['text_cleaned'] = df_full['text'].apply(clean_and_mask)\n",
    "\n",
    "# Salvataggio CSV per controllo\n",
    "df_full.to_csv(\"dataset_training_final.csv\", index=False)\n",
    "print(\"üíæ Dataset salvato per verifica in 'dataset_training_final.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T08:54:34.854525Z",
     "iopub.status.busy": "2025-11-25T08:54:34.853701Z",
     "iopub.status.idle": "2025-11-25T09:01:38.929550Z",
     "shell.execute_reply": "2025-11-25T09:01:38.928878Z",
     "shell.execute_reply.started": "2025-11-25T08:54:34.854500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80344dcb4ddd4b81b4b8d8c1d2e14b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca79478b87643cf89178c52b124ad84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_47/542077269.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Inizio Addestramento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [828/828 06:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.006166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello salvato in ./modello_finale\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. FINE-TUNING E PREDIZIONE\n",
    "# ==========================================\n",
    "\n",
    "# Setup Modello\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODELLO_BASE, num_labels=2).to(device)\n",
    "\n",
    "# Argomenti Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./securebert_cti_output\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, # Se usi GPU P100 puoi provare 32\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,             # 3 epoche per sicurezza\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")\n",
    "\n",
    "print(\"üî• Inizio Addestramento...\")\n",
    "trainer.train()\n",
    "\n",
    "# Salvataggio Modello per uso futuro (nella cartella Output di Kaggle)\n",
    "model.save_pretrained(\"./modello_finale\")\n",
    "tokenizer.save_pretrained(\"./modello_finale\")\n",
    "print(\"‚úÖ Modello salvato in ./modello_finale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T09:04:17.647558Z",
     "iopub.status.busy": "2025-11-25T09:04:17.646858Z",
     "iopub.status.idle": "2025-11-25T09:04:17.720550Z",
     "shell.execute_reply": "2025-11-25T09:04:17.720011Z",
     "shell.execute_reply.started": "2025-11-25T09:04:17.647534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST ---\n",
      "üî¥ CYBER THREAT (100.0%) | User clicked on a malicious link t.me/fake_support which dow...\n",
      "üî¥ CYBER THREAT (100.0%) | New CVE-2023-4455 discovered in Apache servers. Update immed...\n",
      "üî¥ CYBER THREAT (100.0%) | Firewall blocked inbound connection from 192.168.0.100 to po...\n",
      "üü¢ RUMORE/SAFE (0.0%) | Buy this new iPhone for only $999! Best price ever....\n",
      "üü¢ RUMORE/SAFE (0.0%) | Can you send me the link to the zoom meeting for the party?...\n",
      "üü¢ RUMORE/SAFE (0.0%) | I just configured my printer on static IP 192.168.1.50, it w...\n",
      "üü¢ RUMORE/SAFE (0.0%) | Hi my name is Alessandro ...\n"
     ]
    }
   ],
   "source": [
    "# --- TEST RAPIDO ---\n",
    "def predict_message(message):\n",
    "    model.eval()\n",
    "    processed_text = clean_and_mask(message)\n",
    "    inputs = tokenizer(processed_text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    score = probs[0][1].item() # Probabilit√† classe 1\n",
    "    \n",
    "    # Threshold personalizzabile (es. sopra il 70% √® Cyber)\n",
    "    label_str = \"üî¥ CYBER THREAT\" if score > 0.5 else \"üü¢ RUMORE/SAFE\"\n",
    "    return f\"{label_str} ({score:.1%}) | {message[:60]}...\"\n",
    "\n",
    "\n",
    "print(\"\\n--- TEST ---\")\n",
    "\n",
    "english_msgs = [\n",
    "    # 1. PHISHING (Chiaro contesto di minaccia)\n",
    "    \"User clicked on a malicious link t.me/fake_support which downloaded a payload.\",\n",
    "    \n",
    "    # 2. VULNERABILITY (Linguaggio tecnico da report)\n",
    "    \"New CVE-2023-4455 discovered in Apache servers. Update immediately.\",\n",
    "    \n",
    "    # 3. NETWORK LOG (Tipico log di firewall)\n",
    "    \"Firewall blocked inbound connection from 192.168.0.100 to port 22 (SSH).\",\n",
    "    \n",
    "    # 4. RUMORE (Spam commerciale con numeri/prezzi)\n",
    "    \"Buy this new iPhone for only $999! Best price ever.\",\n",
    "    \n",
    "    # 5. RUMORE (Chat generica, anche se contiene parole 'tecniche' come 'link')\n",
    "    \"Can you send me the link to the zoom meeting for the party?\",\n",
    "    \n",
    "    # 6. AMBIGUO (Contiene un IP ma √® innocuo - Test difficile)\n",
    "    \"I just configured my printer on static IP 192.168.1.50, it works fine.\",\n",
    "    \"Hi my name is Alessandro \"\n",
    "]\n",
    "\n",
    "for msg in english_msgs:\n",
    "    print(predict_message(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T09:06:48.629934Z",
     "iopub.status.busy": "2025-11-25T09:06:48.628988Z",
     "iopub.status.idle": "2025-11-25T09:06:48.717901Z",
     "shell.execute_reply": "2025-11-25T09:06:48.717081Z",
     "shell.execute_reply.started": "2025-11-25T09:06:48.629894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ CYBER THREAT (73.9%) | The doctor said this virus is highly contagious and has infe...\n",
      "üü¢ RUMORE/SAFE (0.0%) | We need to raid the enemy base tonight, their defense bot is...\n",
      "üü¢ RUMORE/SAFE (0.0%) | I had to kill the python process listening on port 8080 beca...\n",
      "üü¢ RUMORE/SAFE (0.0%) | He managed to exploit the loophole in the tax system to save...\n",
      "üü¢ RUMORE/SAFE (0.0%) | Urgent: Your payroll direct deposit has been rejected. Pleas...\n",
      "üü¢ RUMORE/SAFE (7.0%) | I am writing a thesis on how Stuxnet used zero-day vulnerabi...\n",
      "üü¢ RUMORE/SAFE (0.0%) | Hey d.ude, download this t00l to c.r.a.c.k the w1fi p@ssw0rd...\n"
     ]
    }
   ],
   "source": [
    "tricky_msgs = [\n",
    "    # 1. CONTESTO MEDICO/BIOLOGICO (False Positive Trap)\n",
    "    # Contiene \"virus\", \"infected\", \"spread\". Il modello capir√† che non si parla di PC?\n",
    "    \"The doctor said this virus is highly contagious and has infected the whole family.\",\n",
    "\n",
    "    # 2. CONTESTO GAMING (False Positive Trap)\n",
    "    # I gamer usano parole come \"attack\", \"raid\", \"bot\", \"kill\". \n",
    "    # SecureBERT capir√† che √® Minecraft/WoW e non un attacco hacker?\n",
    "    \"We need to raid the enemy base tonight, their defense bot is too strong, kill it!\",\n",
    "\n",
    "    # 3. IT SUPPORT / DEV (La pi√π difficile)\n",
    "    # Sembra un attacco (kill process, port, listen), ma √® un sistemista che lavora.\n",
    "    # Spesso i modelli CTI segnano questo come minaccia (False Positive).\n",
    "    \"I had to kill the python process listening on port 8080 because it was stuck.\",\n",
    "\n",
    "    # 4. METAFORE (False Positive Trap)\n",
    "    # \"Exploit\" usato in senso non informatico.\n",
    "    \"He managed to exploit the loophole in the tax system to save money.\",\n",
    "\n",
    "    # 5. SOCIAL ENGINEERING \"PURO\" (False Negative Trap)\n",
    "    # Nessun link, nessun IP, nessun malware. Solo manipolazione psicologica.\n",
    "    # Se il modello cerca solo parole tecniche, questo passer√† come SICURO (Errore).\n",
    "    \"Urgent: Your payroll direct deposit has been rejected. Please reply immediately to verify info.\",\n",
    "\n",
    "    # 6. EDUCATIONAL / STORICO (Gray Area)\n",
    "    # Parla di minacce reali (Stuxnet, Zero-day) ma in contesto di studio.\n",
    "    # Tecnicamente √® CTI (parla di cyber), ma non √® un allarme attivo.\n",
    "    \"I am writing a thesis on how Stuxnet used zero-day vulnerabilities to target SCADA systems.\",\n",
    "\n",
    "    # 7. TYPOSQUATTING / OBFUSCATION (False Negative Trap)\n",
    "    # L'hacker cerca di fregare il tokenizer rompendo le parole.\n",
    "    # Il modello riuscir√† a vedere \"password\" e \"crack\" in mezzo al rumore?\n",
    "    \"Hey d.ude, download this t00l to c.r.a.c.k the w1fi p@ssw0rd.\"\n",
    "]\n",
    "\n",
    "for msg in tricky_msgs:\n",
    "    print(predict_message(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T09:13:54.452473Z",
     "iopub.status.busy": "2025-11-25T09:13:54.452202Z",
     "iopub.status.idle": "2025-11-25T09:14:19.151544Z",
     "shell.execute_reply": "2025-11-25T09:14:19.150757Z",
     "shell.execute_reply.started": "2025-11-25T09:13:54.452454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Sto comprimendo la cartella './modello_finale'...\n",
      "‚úÖ Compressione riuscita! File creato: modello_finale.zip\n",
      "‚¨áÔ∏è Clicca sul link qui sotto per scaricare il tuo modello:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='modello_finale.zip' target='_blank'>modello_finale.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/modello_finale.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURAZIONE\n",
    "# ==========================================\n",
    "# Il nome della cartella che vuoi scaricare (quella creata dal tuo training)\n",
    "CARTELLA_DA_SCARICARE = \"./modello_finale\" \n",
    "\n",
    "# Il nome che vuoi dare al file zip finale\n",
    "NOME_FILE_ZIP = \"modello_finale\"\n",
    "\n",
    "# ==========================================\n",
    "# COMPRESSIONE E DOWNLOAD\n",
    "# ==========================================\n",
    "# Verifica se la cartella esiste\n",
    "if os.path.exists(CARTELLA_DA_SCARICARE):\n",
    "    print(f\"üì¶ Sto comprimendo la cartella '{CARTELLA_DA_SCARICARE}'...\")\n",
    "    \n",
    "    # Crea l'archivio (shutil aggiunge .zip in automatico)\n",
    "    shutil.make_archive(NOME_FILE_ZIP, 'zip', CARTELLA_DA_SCARICARE)\n",
    "    \n",
    "    print(f\"‚úÖ Compressione riuscita! File creato: {NOME_FILE_ZIP}.zip\")\n",
    "    print(\"‚¨áÔ∏è Clicca sul link qui sotto per scaricare il tuo modello:\")\n",
    "    \n",
    "    # Genera il link cliccabile\n",
    "    display(FileLink(f'{NOME_FILE_ZIP}.zip'))\n",
    "else:\n",
    "    print(f\"‚ùå ERRORE: La cartella '{CARTELLA_DA_SCARICARE}' non esiste.\")\n",
    "    print(\"Controlla di aver eseguito la cella di salvataggio (model.save_pretrained).\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
